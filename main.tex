% ---------------------------------------------------------------------------
% Author guideline and sample document for EG publication using LaTeX2e input
% D.Fellner, v1.20, Jan 18, 2023

\documentclass{egpubl}
\usepackage{sca2024p}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{dfadobe}  
\usepackage{tikz}
\usepackage{overpic}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{booktabs} % For \toprule, \midrule, \bottomrule
\usepackage{array} 
\usepackage{cite}  % comment out for biblatex with backend=biber
\usepackage{multirow}
\usepackage{enumitem}
% ---------------------------
%\biberVersion
\BibtexOrBiblatex
%\usepackage[backend=biber,bibstyle=EG,citestyle=alphabetic,backref=true]{biblatex} 
%\addbibresource{egbibsample.bib}
% ---------------------------  
\electronicVersion
\PrintedOrElectronic
% for including postscript figures
% mind: package option 'draft' will replace PS figure by a filename within a frame
% \ifpdf \usepackage[pdftex]{graphicx} \pdfcompresslevel=9
% \else \usepackage[dvips]{graphicx} \fi


\usepackage{egweblnk} 
\usetikzlibrary{arrows, decorations.markings, arrows.meta,positioning,shadows,shapes.geometric,automata,positioning,fit,arrows.meta,calc,bending}
 
% --- for  Annual CONFERENCE
% \ConferenceSubmission   % uncomment for Conference submission
% \ConferencePaper        % uncomment for (final) Conference Paper
% \STAR                   % uncomment for STAR contribution
% \Tutorial               % uncomment for Tutorial contribution
% \ShortPresentation      % uncomment for (final) Short Conference Presentation
% \Areas                  % uncomment for Areas contribution
% \Education              % uncomment for Education contribution
\WsPoster                 % uncomment for Poster contribution
% \DC                     % uncomment for Doctoral Consortium
%
% --- for  CGF Journal
% \JournalSubmission    % uncomment for submission to Computer Graphics Forum
% \JournalPaper         % uncomment for final version of Journal Paper
%
% --- for  CGF Journal: special issue
% \SpecialIssueSubmission    % uncomment for submission to , special issue
% \SpecialIssuePaper         % uncomment for final version of Computer Graphics Forum, special issue
%                          % EuroVis, SGP, Rendering, PG
% --- for  EG Workshop Proceedings
% \WsSubmission      % uncomment for submission to EG Workshop
% \WsPaper           % uncomment for final version of EG Workshop contribution
% \WsSubmissionJoint % for joint events, for example ICAT-EGVE
% \WsPaperJoint      % for joint events, for example ICAT-EGVE
% \Expressive        % for SBIM, CAe, NPAR
% \DigitalHeritagePaper
% \PaperL2P          % for events EG only asks for License to Publish

% --- for EuroVis 
% for full papers use \SpecialIssuePaper
% \STAREurovis   % for EuroVis additional material 
% \EuroVisPoster % for EuroVis additional material 
% \EuroVisShort  % for EuroVis additional material
% \MedicalPrize  % uncomment for Medical Prize (Dirk Bartz) contribution, since 2021 part of EuroVis

% Licences: for CGF Journal (EG conf. full papers and STARs, EuroVis conf. full papers and STARs, SR, SGP, PG)
% please choose the correct license
%\CGFStandardLicense
%\CGFccby
%\CGFccbync
%\CGFccbyncnd

% !! *please* don't change anything above
% !! unless you REALLY know what you are doing
% ------------------------------------------------------------------------

% end of prologue

\title{Markerless Multi-view Multi-person Tracking for Combat Sports}

% for anonymous conference submission please enter your SUBMISSION ID
% instead of the author's name (and leave the affiliation blank) !!
% for final version: please provide your *own* ORCID in the brackets following \orcid; see https://orcid.org/ for more details.
\author[Hossein, Labbé, and Andrews]
{\parbox{\textwidth}{\centering 
        Hossein Feiz$^1$, David Labbé$^1$, Sheldon Andrews$^1$
        }
        \\
{\parbox{\textwidth}{\centering 
        $^1$École de technologie supérieure, Montreal, Canada
       }
}
}
% ------------------------------------------------------------------------

% if the Editors-in-Chief have given you the data, you may uncomment
% the following five lines and insert it here
%
% \volume{36}   % the volume in which the issue will be published;
% \issue{1}     % the issue number of the publication
% \pStartPage{1}      % set starting page


%-------------------------------------------------------------------------
\begin{document}

% uncomment for using teaser
% \teaser{
%  \includegraphics[width=0.9\linewidth]{pipeline.pdf}
%  \centering
%   \caption{The pipeline begins with generating bounding boxes  and robust tracking  for each individual in the scene. These tracking results are used to produce 2D poses. The triangulation process, produces smooth 3D keypoints. The kinematics optimization step incorporates the 2D and 3D keypoints, to create the SMPL parameters ($\mathbf{\theta}$, $\mathbf{\beta}$). The 3D relative joint positions, initial pose state  and velocity state of the humanoid, serve as a reference for a dynamic optimizer to correct any artifacts in the motion.}
% \label{fig:teaser}
% }

\maketitle
%-------------------------------------------------------------------------

\begin{abstract}
   We introduce a novel framework for 3D pose estimation in combat sports. Utilizing a sparse multi-camera setup, our approach employs a computer vision-based tracker to extract 2D pose predictions from each camera view, enforcing consistent tracking targets across views with epipolar constraints and long-term video object segmentation. Through a top-down transformer-based approach, we ensure high-quality 2D pose extraction. We estimate the 3D position via weighted triangulation, spline fitting and extended Kalman filtering. By employing kinematic optimization and physics-based trajectory refinement, we achieve state-of-the-art accuracy and robustness under challenging conditions such as occlusion and rapid movements. Experimental validation on diverse datasets, including a custom dataset featuring elite boxers, underscores the effectiveness of our approach. Additionally, we contribute a valuable sparring video dataset to advance research in multi-person tracking for sports.

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010371.10010352.10010381</concept_id>
<concept_desc>Computing methodologies~Pose Estimation</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010371.10010352.10010382</concept_id>
<concept_desc>Computing methodologies~Motion synthesis</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[300]{Computing methodologies~Pose Estimation}
\ccsdesc[300]{Computing methodologies~Optimization}


\printccsdesc   
\end{abstract}  
%-------------------------------------------------------------------------
\section{Introduction}
Combat sports present significant challenges for motion capture due to numerous close-proximity interactions and frequently crowded backgrounds. Optical marker-based tracking, while precise in controlled environments, becomes impractical due to dynamic motions and frequent collisions leading to calibration issues. Inertial measurement unit (IMU) based solutions suffer from global positional drift, affecting inter-athlete distances. Monocular vision-based approaches, though freeing athletes from tracking equipment, often lack precision due to frequent occlusions. However, these occlusions can be mitigated by incorporating data from multiple camera viewpoints, a cornerstone of our tracking pipeline.

We propose a multi-stage, multi-view tracking pipeline shown in Fig~\ref{fig:pipeline} designed to reconstruct high-quality 3D motion of athletes engaged in combat sports such as boxing. Our approach integrates 2D keypoints from multiple camera views through kinematic optimization, followed by physics-based trajectory refinement using model predictive control to eliminate non-physical artifacts. 
The contributions of our work are summarized as follows:
\begin{itemize}
    \item A comprehensive multi-camera multi-person physics-based pose estimation framework designed for high-quality 3D pose estimation using as few as three cameras.
    \item A robust triangulation technique employing spline fitting and Kalman filtering to generate consistent and smooth 3D positions.
    \item A high-quality dataset of >~20 minutes of video footage featuring elite boxers during sparring sessions that encompasses several boxing styles, plus a multi-view dataset of motions representative of combat sports and synchronized with ground truth from an optical marker tracking system. We will release these datasets and the solved motions.
\end{itemize}



\label{sec:results} 


% \begin{table*}[t]
%   \caption{Comparison of PCP[\% $\uparrow$] results on the Campus and Shelf datasets.}
%   \centering
%   \resizebox{\textwidth}{!}{%
%     \begin{tabular}{@{}r|cccc|cccc@{}}
%       \toprule
%       Method & \multicolumn{4}{c|}{Campus} & \multicolumn{4}{c}{Shelf} \\
%       \cmidrule(r){2-5} \cmidrule(l){6-9}
%       & Actor 1 & Actor 2 & Actor 3 & Avg. & Actor 1 & Actor 2 & Actor 3 & Avg.\\
%       \midrule
  
%      ~\cite{wang2021} & 99.3 & 95.1 & 97.8 & 97.4 & 98.2 & 94.1 & 97.4 & 96.6 \\ 
%      ~\cite{yang2023unified} & 98.2 & 94.6 & 98.2 & 97.0 & 99.5 & 96.0 & 97.7 & 97.7 \\       
%       ours (Triangulation) & \textbf{99.6} & 92.2 & 97.6 & 96.5 & \textbf{99.8} & 95.4 & \textbf{98.6} & \textbf{97.9} \\ 
%       ours (Kinematics) & 98.5 & 93.5 & 94.4 & 95.5 & \textbf{99.8} & \textbf{97.6} & \textbf{98.6} & \textbf{98.6} \\
%       ours (Dynamics) & 97.7 & 93.6 & 94.2 & 95.1 & 97.1 & \textbf{97.6} & 97.2 & 97.3 \\
%       \bottomrule
%     \end{tabular}%
%   }
%   \label{tab:benchmark}
% \end{table*}
\section{Pose Estimation}

Our tracking pipeline is summarized in Fig.~\ref{fig:pipeline}. We describe the main stages below.
%-------------------------------------------------------------------------

\textbf{Tracking 2D and 3D:} Using epipolar constraints and long-term video object segmentation~\cite{cheng2022xmem} we produce consistent ids for everyone, these ids are used to produce 2D joints positions using~\cite{xu2022vitpose} for tracking targets. We then use linear triangulation and Kalman estimation to produce robust 3D joints positions for each individual, even in the presence of noise and outliers.   
\begin{figure*}[!ht]
\includegraphics[width=0.75\linewidth]{pipeline.pdf}
 \centering
  \caption{Our pipeline begins with generating bounding boxes and tracking ids for each individual in the scene, which are then used to produce 2D poses for each individual for each view $j$. A triangulation process is then used to compute 3D keypoints. The kinematics optimization step incorporates the 2D and 3D keypoints to compute SMPL parameters ($\mathbf{\theta}$, $\mathbf{\beta}$). The 3D relative joint positions, initial pose state and velocity state of the humanoid, serve as a reference for a dynamic optimizer to correct artifacts in the motion.}
  \label{fig:pipeline}
  \vspace{-8pt}
\end{figure*}
\begin{figure*}[htb]
    \centering
    \begin{minipage}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/campus2.png}
    \end{minipage}%
    \hspace{0.01\textwidth}
    \begin{minipage}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/shelf.png}
    \end{minipage}%
    \hspace{0.01\textwidth}
    \begin{minipage}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/supp.png}
    \end{minipage}%
    \caption{Poses estimated from the Campus (left), Shelf (middle) datasets, and our custom supplementary (right) dataset. }
    \label{fig:qualitative}
    \vspace{-16pt}
\end{figure*}
%-------------------------------------------------------------------------

\textbf{Kinematics Optimization:} The kinematics optimization focuses on refining the pose estimation of athletes using 2D and 3D keypoint data. Fig~\ref{fig:qualitative} shows the results of the kinematics stage on different datasets.
%Employing the SMPL model, the optimization aims to minimize the disparity between model joints and observed data while ensuring temporal coherence and natural movement. 
The optimization initializes shape parameters ($\beta \in \mathbb{R}^{10}$) of the SMPL model based on 3D keypoints obtained through triangulation. Subsequently, it iteratively adjusts shape and pose parameters ($\theta \in \mathbb{R}^{72}$) to refine the pose estimation based on objectives for smoothness, similarity to human motion priors, and alignment with both 2D re-projection evidence and triangulated 3D keypoints. We summarize these objective terms below: 
\begin{itemize}
    \item \textbf{2D Re-projection  loss} ($\mathrm{L}_\text{2D}$): Aligns 3D with 2D keypoints across multiple views, emphasizing high-confidence joints.
    \item \textbf{3D Alignment loss} ($\mathrm{L}_\text{3D}$): Distance between predicted joint locations and triangulated keypoints, weighted by their confidence.
    \item \textbf{Smoothness loss} ($\mathrm{L}_\text{smooth}$): Promotes temporal coherency in pose transitions from frame-to-frame.
    \item \textbf{Prior losses} ($\mathrm{L}_{\text{GMM}}$, $\mathrm{L}_{\text{Vposer}}$): Gaussian Mixture Model (GMM) and Vposer~\cite{Vposer} priors to penalize unnatural poses.
\end{itemize}
%-------------------------------------------------------------------------

\textbf{Dynamics Optimization:} Motions produced by the kinematic stage often contain high-frequency jitter and foot skating. We found that a dynamics optimization using a physics-based humanoid model helps to mitigate these artifacts. The model consists of an articulated rigid-body structure with 56 joint-angle degrees of freedom, plus 6 degrees of freedom for the root motion. Capsule collision geometry aligned with SMPL landmarks comprises the shape. The dynamics optimization refines motion trajectories from the kinematics stage by considering joint torques and biomechanical constraints within the physical environment. Joint torques are computd using an iLQR algorithm~\cite{howell2022}, This approach accounts for contact forces and body dynamics, enhancing the overall quality and naturalness of the generated motions by iteratively refining control trajectories over short time horizons. Table~\ref{tab:physics} presents quantitative metrics computed using our supplementary dataset on the motions produced by the kinematics optimizaton stage and after the dynamics optimization. The dynamics optimization clearly increases the naturalness of the solved motions.
%mean per joint position error (MPJPE), foot skating and floating error, and smoothness are presented in Table


\begin{table}[h]
    \caption{MPJPE, foot skating and floating~\cite{Xie:2021aa}, and smoothness~\cite{Shimada_2020} metrics before and after the dynamics optimization.}
    \centering
    \begin{tabular}{cccccc}
        \toprule
        & \, & $e_{\text{MPJPE}}\downarrow$ & $e_{\text{foot},z}\downarrow$ & $e_{\text{foot},v_{xy}}\downarrow$ & $e_{\text{smooth}}\downarrow$ \\
        \midrule
        \midrule
        & Kinematics & 41.2 &  16.4 & 2.2 & 6.1 \\
        & Dynamics & 38.4 & 8.1 & 0.3 & 4.6 \\
        \bottomrule
    \end{tabular}
    \label{tab:physics}
    \vspace{-12pt}
\end{table}

\bibliographystyle{eg-alpha-doi} 
\bibliography{bibliography} 

\end{document}

